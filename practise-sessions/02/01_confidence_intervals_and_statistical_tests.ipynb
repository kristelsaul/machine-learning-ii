{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence intervals and statistical tests\n",
    "\n",
    "Hypothesis testing and confidence intervals are the most basic but also the most powerful concepts of classical statistics. \n",
    "In the following, we will show how these concepts are interlinked and how one should interpret results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from tqdm import tnrange\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from common import *\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. The number of heads in a finite sequence of coin flips\n",
    "\n",
    "It is easy to verify that the probability to get exactly $k$ ones in $n$ independent identical trials $B_1,\\ldots,B_n$ is\n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[B_1+\\ldots+B_n=k]=\\binom{n}{k}p^k(1-p)^{n-k}\n",
    "\\end{align*}\n",
    "\n",
    "where $p$ is the probability to get one in a trial $B_i$. \n",
    "The corresponding distribution is known as a binomial distribution and is available as `scipy.stats.binom`:\n",
    "\n",
    "* `rvs` is for sampling \n",
    "* `pmf` is for computing probabilities $\\Pr[B_1+\\ldots+B_n=k]$\n",
    "* `cdf` is for computing probabilities $\\Pr[B_1+\\ldots+B_n\\leq k]$\n",
    "* `ppf` is for computing quantiles, i.e., for solving $\\mathrm{argmax}_k\\Pr[B_1+\\ldots+B_n\\leq k]\\leq\\alpha$\n",
    "* `mean`, `var`, `median`, ... for standard statistical parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of basic aspects of a binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>pr</th>\n",
       "      <th>lower_tail</th>\n",
       "      <th>upper_tail</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.907349e-05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.811981e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.087189e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.620552e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.478577e-02</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.696442e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.392883e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.201344e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.601791e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.761971e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.601791e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.201344e-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7.392883e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3.696442e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.478577e-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>4.620552e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.087189e-03</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.811981e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.907349e-05</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k            pr  lower_tail  upper_tail   tail\n",
       "0    0  9.536743e-07        True       False   True\n",
       "1    1  1.907349e-05        True       False   True\n",
       "2    2  1.811981e-04        True       False   True\n",
       "3    3  1.087189e-03        True       False   True\n",
       "4    4  4.620552e-03        True       False   True\n",
       "5    5  1.478577e-02        True       False   True\n",
       "6    6  3.696442e-02       False       False  False\n",
       "7    7  7.392883e-02       False       False  False\n",
       "8    8  1.201344e-01       False       False  False\n",
       "9    9  1.601791e-01       False       False  False\n",
       "10  10  1.761971e-01       False       False  False\n",
       "11  11  1.601791e-01       False       False  False\n",
       "12  12  1.201344e-01       False       False  False\n",
       "13  13  7.392883e-02       False       False  False\n",
       "14  14  3.696442e-02       False       False  False\n",
       "15  15  1.478577e-02       False        True   True\n",
       "16  16  4.620552e-03       False        True   True\n",
       "17  17  1.087189e-03       False        True   True\n",
       "18  18  1.811981e-04       False        True   True\n",
       "19  19  1.907349e-05       False        True   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20\n",
    "k = range(n)\n",
    "\n",
    "# Tabulated binomial distribution with tails containing up to 2.5% of probability mass\n",
    "pmf = (DataFrame({'k':list(k), 'pr': binom.pmf(k, n, p=0.5)})\n",
    "       .assign(lower_tail = (k < binom.ppf(0.025, n, p=0.5)))\n",
    "       .assign(upper_tail = (k > binom.ppf(0.975, n, p=0.5)))\n",
    "       .assign(tail = lambda df: df['lower_tail'] | df['upper_tail']))\n",
    "\n",
    "display(pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PlotnineError",
     "evalue": "'Unknown guide: False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPlotnineError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m p \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m+\u001b[39m scale_x_continuous(name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m scale_y_continuous(name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m p \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m+\u001b[39m scale_fill_manual(guide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinomial_distribution.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m display(p)\n",
      "File \u001b[0;32m~/Library/miniforge3/envs/huggingface/lib/python3.10/site-packages/plotnine/ggplot.py:673\u001b[0m, in \u001b[0;36mggplot.save\u001b[0;34m(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave\u001b[39m(\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    626\u001b[0m     filename: Optional[\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m BytesIO] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    636\u001b[0m ):\n\u001b[1;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    Save a ggplot object as an image file\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;124;03m        Additional arguments to pass to matplotlib `savefig()`.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     sv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimitsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimitsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m plot_context(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrc_context:\n\u001b[1;32m    687\u001b[0m         sv\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msv\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/miniforge3/envs/huggingface/lib/python3.10/site-packages/plotnine/ggplot.py:621\u001b[0m, in \u001b[0;36mggplot.save_helper\u001b[0;34m(self, filename, format, path, width, height, units, dpi, limitsize, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dpi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheme \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheme \u001b[38;5;241m+\u001b[39m theme(dpi\u001b[38;5;241m=\u001b[39mdpi)\n\u001b[0;32m--> 621\u001b[0m figure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mpl_save_view(figure, fig_kwargs)\n",
      "File \u001b[0;32m~/Library/miniforge3/envs/huggingface/lib/python3.10/site-packages/plotnine/ggplot.py:282\u001b[0m, in \u001b[0;36mggplot.draw\u001b[0;34m(self, show)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# setup\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfacet\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheme\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Drawing\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/miniforge3/envs/huggingface/lib/python3.10/site-packages/plotnine/guides/guides.py:174\u001b[0m, in \u001b[0;36mguides._setup\u001b[0;34m(self, plot)\u001b[0m\n\u001b[1;32m    172\u001b[0m     g \u001b[38;5;241m=\u001b[39m Registry[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguide_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(g, guide):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PlotnineError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown guide: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m g\u001b[38;5;241m.\u001b[39msetup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lookup[(scale\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, ae)] \u001b[38;5;241m=\u001b[39m (scale, g)\n",
      "\u001b[0;31mPlotnineError\u001b[0m: 'Unknown guide: False'"
     ]
    }
   ],
   "source": [
    "p = ggplot(pmf)\n",
    "p = p + geom_col(aes(x = 'k', y = 'pr', fill='tail'), width = 0.8)\n",
    "p = p + geom_vline(xintercept = binom.ppf(0.025, n=20, p=0.5) - 0.5, linetype ='--', size = 1)\n",
    "p = p + geom_vline(xintercept = binom.ppf(0.975, n=20, p=0.5) + 0.5, linetype ='--', size = 1)\n",
    "p = p + geom_vline(xintercept = binom.ppf(0.500, n=20, p=0.5) + 0.0, linetype ='-',  size = 1)\n",
    "p = p + scale_x_continuous(name = '') + scale_y_continuous(name = '')\n",
    "p = p + scale_fill_manual(guide = False, values = ['red', 'blue'])\n",
    "p.save('binomial_distribution.pdf', path='results', height=6, width=12, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Confidence intervals for the probability\n",
    "\n",
    "The most naive way to find confidence intervals for a binomial distribution is the following:\n",
    "* Define a statistical test for all possible values of the parameter $p\\in[0,1]$ by computing $2.5\\%$ and $97.5\\%$ quantiles.\n",
    "* Tabulate for each observed integer value $k$ what tests are passed and extend the corresponding parameter set into an interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate quantiles for all parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "tdf = DataFrame(index = range(11)).assign(p = lambda df: df.index.values/(len(df)-1))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['q1'] = tdf['p'].apply(lambda p: binom.ppf(0.025, n, p))\n",
    "tdf['q2'] = tdf['p'].apply(lambda p: binom.ppf(0.975, n, p))\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's correct the obvious scipy error\n",
    "# They never manage to keep both ends correct at the sam time\n",
    "tdf.loc[0, 'q1'] = 0\n",
    "tdf.loc[10, 'q1'] = 20\n",
    "display(tdf)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(tdf)\n",
    "p + geom_segment(aes(x = 'q1', xend = 'q2', y = 'p', yend = 'p')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate accepted hypotheses for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =[None] * 21\n",
    "for k in range(21):\n",
    "    df[k] = DataFrame({'observed_k': k, 'accepted_p': tdf.loc[(tdf['q1'] <= k) & (k<= tdf['q2']), 'p']})\n",
    "df = pd.concat(df, ignore_index=True)\n",
    "head(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we use a finite grid, we must extend the interval to bordering grid points\n",
    "sdf = (df.groupby(['observed_k']).aggregate(['min', 'max'])\n",
    "       .pipe(lambda df: reset_column_index(df, 0))\n",
    "       .reset_index()\n",
    "       .assign(maxp = lambda df: df['max'] + 0.1)\n",
    "       .assign(minp = lambda df: df['min'] - 0.1))\n",
    "\n",
    "mdisplay([head(df), head(sdf)], ['Accepted parameters', 'Extended intervals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of the search procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(tdf)\n",
    "p = p + geom_segment(aes(x = 'q1', xend = 'q2', y = 'p', yend = 'p'), color = 'blue') \n",
    "p = p + geom_point(aes(x = 'observed_k', y = 'accepted_p'), color = 'blue', data = df)\n",
    "p = p + scale_x_continuous(name = '')\n",
    "p = p + scale_y_continuous(name = '', limits=(-0.1, 1.1), breaks = [0, 0.5, 1.0])\n",
    "p.save('bin_conf_intervals_i.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)\n",
    "\n",
    "\n",
    "p = ggplot(df)\n",
    "p = p + geom_segment(aes(x = 'observed_k', xend = 'observed_k', y='minp', yend ='maxp'), color = 'red', data=sdf)\n",
    "p = p + geom_point(aes(x = 'observed_k', y = 'accepted_p'), color = 'blue')\n",
    "p = p + scale_x_continuous(name = '')\n",
    "p = p + scale_y_continuous(name = '', limits=(-0.1, 1.1), breaks = [0, 0.5, 1.0])\n",
    "p.save('bin_conf_intervals_ii.pdf', path='results', height=6, width=6, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. What does the confidence level mean?\n",
    "\n",
    "The confidence level is a subtle concept. Most importantly, the confidence level **is not** a probability that the true parameter value is inside the confidence interval. Confidence level $\\alpha$ shows uncertaintly related to the average case behaviour.\n",
    "\n",
    "If one could repeat the data collection infinite amount of times and compute the confidence interval for each of them then in $\\alpha$-fraction of runs the true parameter value is inside the interval.\n",
    "This does not say anything about the particular run and a confidence interval we are interested in.\n",
    "\n",
    "To get an actionable outcome, we must use ultra-fequentist resolution and state that the true value is inside the interval as events with probability $1-\\alpha$ do not happen. \n",
    "The latter is slighty silly for $90\\%$ and $95\\%$ confidence intervals but this is how engineers work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example case\n",
    "\n",
    "In the following we conduct simulations to illustrate these concepts:\n",
    "* The parameter to be estimated will be the  probability $\\Pr[B_i=1]$.\n",
    "* The observed value will be the number of heads in the coinflipping experiment.\n",
    "\n",
    "We use the method [statsmodels.stats.proportion.proportion_confint](https://www.statsmodels.org/dev/generated/statsmodels.stats.proportion.proportion_confint.html) from `statsmodels` to compute confidence intervals in the experiment.\n",
    "This function implements six different methods for computing confidence intervals.\n",
    "We use `binom_test` as it coincides with the method we described earlier.\n",
    "\n",
    "**Note:** \n",
    "* This method may or may not work for current version of `statmodels`. \n",
    "* If it does not work replace `binom_test` with `normal` that swithces the exact method with approximate method -- the tails are not quaranteed to contain exactly 5% of probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert proportion_confint(10, nobs=10, alpha = 0.05, method = 'binom_test'), 'Statsmodel package fails again'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 40\n",
    "\n",
    "# Confidence intervals at significance level 5%\n",
    "# Variable y is just for visualisation\n",
    "obs1 = (DataFrame({'k': binom.rvs(n=20, p=0.5, size=r)})\n",
    "        .assign(q1 = lambda df: df['k'].apply(\n",
    "                            lambda k: proportion_confint(k, nobs=n, alpha = 0.05, method = 'binom_test')[0]))\n",
    "        .assign(q2 = lambda df: df['k'].apply(\n",
    "                            lambda k: proportion_confint(k, nobs=n, alpha = 0.05, method = 'binom_test')[1]))\n",
    "        .assign(fails = lambda df: (0.5 < df['q1']) | (df['q2'] < 0.5))\n",
    "        .assign(alpha = r'$\\alpha =95\\%$')\n",
    "        .assign(y = lambda df: (df.index.values + 1)/len(df.index))\n",
    "        )\n",
    "\n",
    "head(obs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence intervals at significance level 20%\n",
    "# Variable y is just for visualisation\n",
    "obs2 = (obs1[['k']]\n",
    "        .assign(q1 = lambda df: df['k'].apply(\n",
    "                                lambda k: proportion_confint(k, nobs=n, alpha = 0.20, method = 'binom_test')[0]))\n",
    "        .assign(q2 = lambda df: df['k'].apply(\n",
    "                                lambda k: proportion_confint(k, nobs=n, alpha = 0.20, method = 'binom_test')[1]))\n",
    "        .assign(fails = lambda df: (0.5 < df['q1']) | (df['q2'] < 0.5))\n",
    "        .assign(alpha = r'$\\alpha =80\\%$')\n",
    "        .assign(y = lambda df: (df.index.values + 1)/len(df.index))\n",
    ")\n",
    "\n",
    "mdisplay([head(obs1), head(obs2)], ['Large intervals', 'Small intervals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ggplot(pd.concat([obs1, obs2]))\n",
    "p = p + geom_segment(aes(x = 'q1', xend = 'q2', y = 'y', yend='y', color = 'fails'))\n",
    "p = p + facet_wrap(['alpha'])\n",
    "p = p + geom_vline(xintercept = 0.5, size = 1.5)\n",
    "p = p + scale_x_continuous(name = '') + scale_y_continuous(name = '')\n",
    "p = p + scale_color_manual(guide = None, values = ['blue', 'red'])\n",
    "p.save('confidence_intervals_example.pdf', path='results', height=6, width=12, verbose=False)\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Comparison of different confidence interval methods (<font color='red'>1p+1p</font>)\n",
    "\n",
    "The function `proportion_confint` implements six different methods for computing confidence intervals. \n",
    "Most of them are approximations. Compare how well these methods work. For that, execute the following simulation:\n",
    "* Sample observations from a binomial distribution.\n",
    "* Compute different confidence intervals for each observation.\n",
    "* Estimate the fraction of correct guesses for each method and tabulate the results using `geom_col`.\n",
    "* Show the expected baseline value on each plot or facet.\n",
    "\n",
    "Try the sample count $n=20$ and the confidence level $\\alpha=90\\%$ and two methods of your choice. \n",
    "Interpret results. Are there any significant differences between different methods? (<font color='red'>1p</font>)\n",
    "You can also visualise the locations of the confidence intervals using `geom_jitter`.\n",
    "\n",
    "Note that most of the methods are approximations and they make an error. Repeat the experiment with confidence level $\\alpha=99\\%$ and compare the results on different sample sizes $n\\in\\{20, 100\\}$. Interpret the results (<font color='red'>1p</font>).    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.4\n",
    "n = 20\n",
    "r = 1000\n",
    "\n",
    "obs = DataFrame({'k': binom.rvs(n=n, p=p, size=r)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['q0']=proportion_confint(obs.loc[:,'k'], nobs=n, alpha = 0.05, method = 'normal')[0]\n",
    "obs['q1']=proportion_confint(obs.loc[:,'k'], nobs=n, alpha = 0.05, method = 'normal')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['fail'] = (obs['q0']>p) |(obs['q1']<p)\n",
    "obs['success'] = ~obs['fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['success'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Confidence intervals and engineering tradeoffs* (<font color='red'>2p</font>)\n",
    "\n",
    "In practice, one often needs to find the right trade-off between the length of the interval and the expected fraction of failures where the true parameter value is outside the interval. Consider the following two-stage measurement scheme. You can first do low-precision measurements to determine the approximate value of $y_0$ and later use high precision measurement device to get the final measurement value. Each low precision measurement costs $0.05$ € and the high precision measurement costs proportionally to the length of the initial interval estimate. A high-precision scan through a unit length interval costs 1 €. \n",
    "\n",
    "Describe at least two possible measurement strategies and use simulation to estimate their efficiency, i.e. the average amount of money needed to get a successful high-precision measurement.\n",
    "During the simulation, assume that the true paramater value $y_0=0.5$ and low quality measurements come from a normal distribution `numpy.random.normal(loc=y_0, scale=0.2)`.\n",
    "\n",
    "As you sample from the normal distribution, you need to find confidence intervals for estimating the mean value of normally distributed samples without knowing the variance. The corresponding method is implemented as [`statsmodels.stats.weightstats.zconfint`](https://www.statsmodels.org/stable/generated/statsmodels.stats.weightstats.zconfint.html#statsmodels.stats.weightstats.zconfint).\n",
    "\n",
    "**Hint:** On possible naive strategy is to do no low-cost measurements and do the full range check. This consts 1 €. Therefore, doing more than 20 low-cost measurements is irrational. It is important that the decreased cost of high-precision scan over confidence interval would be less than the cost of low-precision measurements needed to establish the interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Confidence intervals and multiple hypothesis testing (<font color='red'>1p</font>)\n",
    "\n",
    "Confidence intervals are also impacted by the multiple hypothesis testing problem. Namely, the fraction of possible datasets where two or more confidence intervals hold simultaneously is significantly smaller than the fraction of datasets where one confidence interval holds. \n",
    "\n",
    "Assume that all intervals have the same confidence level $\\alpha$ if we consider them separately. \n",
    "Let $F_i$ denote the event that the $i$th confidence interval is incorrect on the data sample.\n",
    "If we estimate independent parameters, e.g. room temperature and length of a person, the probability that all confidence interval are correct can be computed as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[F_1=0\\wedge \\ldots\\wedge F_m=0] &= \\Pr[F_1=0]\\cdots \\Pr[F_m=0]=(1-\\alpha)^m\n",
    "\\end{align*}\n",
    "\n",
    "By combining binomial approximation\n",
    "\n",
    "\\begin{align*}\n",
    "1-m\\alpha\\lesssim(1-\\alpha)^m \\lesssim 1-m\\alpha + \\frac{m(m-1)}{2}\\alpha^2\n",
    "\\end{align*}\n",
    "\n",
    "with complement rule \n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[F_1=1\\vee \\ldots\\vee F_m=1] = 1 -(1-\\alpha)^m\n",
    "\\end{align*}\n",
    "\n",
    "we get optimistic and pessimistic bounds\n",
    "\n",
    "\\begin{align*}\n",
    "m\\alpha -\\frac{(m\\alpha)^2}{2}\\lesssim \\Pr[F_1=1\\vee \\ldots\\vee F_m=1] \\lesssim m\\alpha \n",
    "\\end{align*}\n",
    "\n",
    "where the quadratic term is tiny compared to the linear term given that $m \\alpha\\ll 1 $. \n",
    "Therefore, the upper bound $m\\alpha$ is quite sharp and cannot be significantly improved.\n",
    "\n",
    "\n",
    "If these intervals are dependent, e.g. we estimate height and weight at the same time or recompute the paremeter based on an extended set of observations, then we can use the only union bound:\n",
    "\n",
    "\\begin{align*}\n",
    "\\Pr[F_1=1\\vee\\ldots\\vee F_m=1] \\leq m\\alpha\\enspace. \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Study the difference between lower and upper bounds for independent tests. Let the target confidence level be $95\\%$. Compute what should be the confidence level $\\alpha$ for an individual interval if we consider $m=1,2,4, \\ldots, 1024$ intervals based on the optimistic and pessimistic estimates. Draw the corresponding lineplot.\n",
    "\n",
    "Verify whether these estimates hold in practice by using samples from a fair coin and compute the corresponding confidence interval for the proportion:\n",
    "* For each run, sample 1024 throws of an unbiased coin.\n",
    "* Estimate $p$ from the first 256, 512, 1024 samples.\n",
    "* You get three dependent confidence intervals.\n",
    "* Estimate the fraction of runs for which $0.5$ is inside of all the intervals.\n",
    "* Compare the result with the optimistic and pessimistic estimates established for independent tests.\n",
    "\n",
    "Interpret results. How easy is it to build meaningful confidence intervals for many parameters if they must hold simultaneously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

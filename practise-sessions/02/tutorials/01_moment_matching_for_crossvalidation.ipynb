{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive moment matching for crossvalidation\n",
    "\n",
    "Let us consider a typical k-fold crossvalidation scheme for $n$ element dataset. Then for the $i$-th split we can measure: \n",
    "\n",
    "* training error (*downward-biased risk estimate*) $S_i$,\n",
    "* test error (*empirical risk*) $E_i$\n",
    "* optimism (*generalisation gap*) $\\Delta_i = E_i-S_i$.\n",
    "\n",
    "All of these values fluctuate (*are random variables*)  due to two sources of randomness:\n",
    "* the choice of splits,\n",
    "* the choice of data sample.\n",
    "\n",
    "Our goal here is to establish, what is the expected value and variance of their arithmetic means\n",
    "\\begin{align*}\n",
    "\\overline{S}&=\\frac{S_1+\\ldots+S_k}{k}\\\\\n",
    "\\overline{E}&=\\frac{E_1+\\ldots+E_k}{k}\\\\\n",
    "\\overline{\\Delta}&=\\frac{\\Delta_1+\\ldots+\\Delta_k}{k}\\\\\n",
    "\\end{align*}\n",
    "The law of large numbers **alludes but not proves** that these averages should converge to normal distributions for two reasons:\n",
    "\n",
    "* they as sums of *near-independent* variables should converge when $k$ approaches infinity;  \n",
    "* each summand as a sum of *near-independent* variables should converge when the dataset size $n$ approaches infinity.\n",
    "\n",
    "The latter allows us to approximate the distributions of $\\overline{S}$, $\\overline{E}$ and $\\overline{\\Delta}$ with a normal distribution $\\mathcal{N}(\\mu,\\sigma)$ as soon as we can approximate their mean $\\mu$ and variance $\\sigma$. Thi in turn allows us to estimate how probable is that the observed mean deviates from the mean $\\mu$ and define some confidence intervals.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from numpy.random import random\n",
    "\n",
    "from plotnine import *\n",
    "\n",
    "# Local imports\n",
    "from convenience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1351430195)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Truly naive view on the crossvalidation\n",
    "\n",
    "Let us substitute crossvalidation scheme with an experiment where we draw $k$ datasets of size $n$ and use them to define each split. \n",
    "Let $A_1,\\ldots, A_k$ be the corresponding training sets, $B_1,\\ldots, B_k$ be the corresponding test sets, and let $f_1,\\ldots, f_k$ be the corresponding predictors trained on respective training sets.\n",
    "\n",
    "### Means\n",
    "\n",
    "As all elements independently and identically sampled, we can easily establish\n",
    "\\begin{align*}\n",
    "\\mathbf{E}(\\overline{S})&=\n",
    "\\mathbf{E}\\left(\\frac{S_1+\\ldots+S_k}{k}\\right) =\\frac{\\mathbf{E}(S_1)+\\ldots+\\mathbf{E}(S_k)}{k}=\\mathbf{E}(S_1)\\\\ \n",
    "\\mathbf{E}(\\overline{E})&\n",
    "=\\mathbf{E}\\left(\\frac{E_1+\\ldots+E_k}{k}\\right) =\\frac{\\mathbf{E}(E_1)+\\ldots+\\mathbf{E}(E_k)}{k} =\\mathbf{E}(E_1)\\\\ \n",
    "\\mathbf{E}(\\overline{\\Delta})&\n",
    "=\\mathbf{E}\\left(\\frac{\\Delta_1+\\ldots+\\Delta_k}{k}\\right) =\\frac{\\mathbf{E}(\\Delta_1)+\\ldots+\\mathbf{E}(\\Delta_k)}{k} =\\mathbf{E}(\\Delta_1)\n",
    "\\end{align*}\n",
    "where the right-hand side expressions are expected values over the standard holdout experiment. Note that the linearity of mean means that the result holds even if we sample the dataset only once and define sets $A_i, B_i$ through a crossvalidation scheme. We must just prove that all splits are equivalent which is obvious when $n$ is a multiple of $k$, as training and test sets in each split have same sizes.   \n",
    "\n",
    "Now we need to understand what are the corresponding expectations:\n",
    "\n",
    "* $\\mathbf{E}(S_1)$ is the expected training error for the holdout scheme;\n",
    "* $\\mathbf{E}(E_1)$ is the expected test error for the holdout scheme;\n",
    "* $\\mathbf{E}(\\Delta_1)$ is the expected optimism for the holdout scheme\n",
    "\n",
    "where the expectation is taken over the choice of $n$ element datasets. These can be viewed as averages of over infinite experiment series where we first sample a dataset and split it into training and holdout set such that the test set is of size $n/k$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variances\n",
    "\n",
    "Let us now consider the variance of these sums under our naive assumption of $k$ independent holdout experiments. Under this assumption the variance is linear and we can easily establish\n",
    "\\begin{align*}\n",
    "\\mathbf{D}(\\overline{S})&=\n",
    "\\mathbf{D}\\left(\\frac{S_1+\\ldots+S_k}{k}\\right) =\\frac{\\mathbf{D}(S_1)+\\ldots+\\mathbf{D}(S_k)}{k^2}=\\frac{\\mathbf{D}(S_1)}{k}\\\\ \n",
    "\\mathbf{D}(\\overline{E})&\n",
    "=\\mathbf{D}\\left(\\frac{E_1+\\ldots+E_k}{k}\\right) =\\frac{\\mathbf{D}(E_1)+\\ldots+\\mathbf{D}(E_k)}{k^2} =\\frac{\\mathbf{D}(E_1)}{k}\\\\ \n",
    "\\mathbf{D}(\\overline{\\Delta})&\n",
    "=\\mathbf{D}\\left(\\frac{\\Delta_1+\\ldots+\\Delta_k}{k}\\right) =\\frac{\\mathbf{D}(\\Delta_1)+\\ldots+\\mathbf{D}(\\Delta_k)}{k^2} =\\frac{\\mathbf{D}(\\Delta_1)}{k}\n",
    "\\end{align*}\n",
    "where the right-hand side expressions are scaled variances over the standard holdout experiment. More refined analysis would prove that the right-hand variance of test error and optimism matches the varinces of the experiment where the holdout set has size $n$. \n",
    "\n",
    "A priori the first simplification does not hold for the true crossvalidation experiment as summands are not independent and thus their correlations cannot be ignored during the simplification. The result can be re-established for test error under the assumption that the dataset is so large that all predictors $f_1,\\ldots,f_k$ coincide on the dataset points. For large enough $n$, this assumption will be satisfied with negligible failure probability but in this case the the crossvalidation is pointless. The second simplification holds as long as $n$ is a multiple of $k$ as all splits are equivalent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consequnces\n",
    "\n",
    "The results established above show that expected values of $\\overline{S}$, $\\overline{E}$ and $\\overline{\\Delta}$ match with the values we want to measure:\n",
    "\n",
    "* expected training error \n",
    "* expected test error\n",
    "* expected optimism\n",
    "\n",
    "but all of them are measured in the experiment where the training set is of $(1-1/k)n$. Moreover **under our fake assumption** all these estimates can be approximated with normal distribution provided that we can find variances on the right-hand side. This variance term determines the length of the confidence interval. \n",
    "\n",
    "The result also indicates that estimates $\\overline{S}$, $\\overline{E}$ and $\\overline{\\Delta}$ are biased:\n",
    "* $\\overline{S}$ **underestimates** the training error as it **increases** with the size;\n",
    "* $\\overline{E}$ **overestimates** the test error as it **decreases** with the size;\n",
    "* $\\overline{\\Delta}$ **overestimates** the optimism as it **decreases** with the size.\n",
    "\n",
    "In practice the bias is small when $n$ is large enough so that adding more data yiels marginal gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Missing links for computing confidence intervals\n",
    "\n",
    "### Traditional method\n",
    "\n",
    "We now need variance estimates for $\\overline{S}$, $\\overline{E}$ and $\\overline{\\Delta}$. Traditionally, these are computed from observed terms in the corresponding arithmetic sums. The corresponding formula for observations $x_1,\\ldots,x_k$ is following\n",
    "\\begin{align*}\n",
    "\\hat{\\sigma}^2 =\\frac{1}{k-1}\\cdot\\sum_{i=1}^k (x_i-\\overline{x})^2\\quad\\text{where}\\quad \\overline{x} = \\frac{1}{n}\\cdot\\sum_{i=1}^k x_i\\enspace.\n",
    "\\end{align*}\n",
    "Mechanical substitution gives us the desired variance estimates. In practice, these can be computed with `np.var` functions. \n",
    "\n",
    "\n",
    "### Alternative view on crossvalidation error\n",
    "\n",
    "However, there are some hidden correspondences to explore.\n",
    "For a predictor $g$, let $L_i(g)=L(g(\\mathbf{x}_i), y_i)$ denote loss on the $i$-th dataset element. Then it is easy to see that average of individual losses can be expressed:   \n",
    "\\begin{align*}\n",
    "\\overline{E}=\\frac{1}{k}\\cdot\\sum_{i=1}^k\\frac{k}{n}\\cdot\\sum_{j=1}^{n/k} L_{n/k(i-1)+j}(f_{k-i+1})\n",
    "=\\frac{1}{n}\\cdot\\sum_{i=1}^n L_i(f_{k-\\lfloor ik/n\\rfloor})\n",
    "\\end{align*}\n",
    "where the horrible indexing just shows that we predict the value using the predictor trained outside of the test split. \n",
    "\n",
    "This allows us to view the crossvalidation as a way to assign non-related prediction for a data point $\\mathbf{x}_i$ by training the model outside the current fold $B_i$. After that we can compute the test error in ordinary way by averaging over individual losses. Our independent split sampling assumption can be viewed in equivalent restatement. For each test fold $B_i$, we randomly sample the training set $A_i$ and use it to compute the predictor $f_i$. Now if we further strengthen the independence assumption and assume that we sample individual training set for each point $\\mathbf{x}_i$. Then we have set of independent risk estimations $L_i(f_i)$ and we can just compute the variance over the set of observations\n",
    "\\begin{align*}\n",
    "L_1(f_{n/k})\\ldots, L_n(f_{1})\\enspace.\n",
    "\\end{align*}\n",
    "This estimate is more imprecise as it also ignores correlations of losses inside the block -- the particular training split can be a particularly good or bad for training.\n",
    "\n",
    "\n",
    "### Alternative view on the training error\n",
    "\n",
    "Similarly, the average of training losses can be expressed:\n",
    "\\begin{align*}\n",
    "\\overline{S}=\\frac{1}{k}\\cdot\\sum_{i=1}^k\\frac{k}{kn-n}\\cdot\\sum_{j\\leq n(i-1)/k\\atop j>ni/k} L_{j}(f_{k-i+1})\n",
    "=\\frac{1}{n}\\cdot\\sum_{i=1}^n \\frac{1}{k-1}\\cdot\\sum_{j\\neq k-\\lfloor ik/n\\rfloor}L_i(f_{j})\n",
    "\\end{align*}\n",
    "where the horrible indexing just shows that for each point we compute the average loss over $k-1$ predictors that were computed on that split. \n",
    "\n",
    "This allows us to view the crossvalidation as a way to assign $k-1$ related predictions for a data point $\\mathbf{x}_i$ by training the model in splits that contain the current fold $B_i$. After that we can compute the training error as double average. Our independent split sampling assumption can be viewed in equivalent restatement. For each test fold $B_i$, we randomly augment the set with an appropriate number of samples to get a training set $A_i$ and use it to compute the predictor $f_i$. We repeat this process $k-1$ times. Now it we further strengthen the independence assumption then for each point we generate $k-1$ testsets that contain it and compute corresponding training error.  Then we have set of independent averages for each training point and can compute the variance over the set of $n$ observations. This estimate is more imprecise as it also ignores correlations of losses due to the fact that different points share same training sets -- the particular training split can be a particularly good or bad for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Concrete computational recepies\n",
    "\n",
    "For simplicity, let us simulate predictions of $10$-fold crossvalidation by random sampling on the dataset of size 20. Let $y=(0,1,0,\\ldots,1,0)$ be the true label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "target   0   1   0   1   0   1   0   1   0   1   0   1   0   1   0   1   0   \n",
       "\n",
       "        17  18  19  \n",
       "target   1   0   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fold 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold 10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "fold 1    0   1   0   0   0   0   1   1   1   1   1   0   1   1   1   0   0   \n",
       "fold 2    1   1   1   1   0   1   1   1   0   0   0   1   0   1   0   1   1   \n",
       "fold 3    1   1   0   0   0   1   1   1   0   1   1   1   1   1   1   1   0   \n",
       "fold 4    1   0   0   0   0   0   1   0   1   0   0   1   0   0   0   1   1   \n",
       "fold 5    0   0   1   0   0   1   0   1   1   0   0   0   1   0   0   0   0   \n",
       "fold 6    1   1   0   1   0   1   0   1   1   1   1   1   0   0   1   0   0   \n",
       "fold 7    1   0   0   0   1   0   1   1   0   0   1   1   0   0   1   0   0   \n",
       "fold 8    1   0   1   0   1   0   0   0   1   1   1   0   1   1   1   0   1   \n",
       "fold 9    1   0   1   0   0   0   0   0   1   1   0   1   0   1   1   1   0   \n",
       "fold 10   0   0   1   0   0   0   1   0   1   1   0   1   1   1   1   1   0   \n",
       "\n",
       "         17  18  19  \n",
       "fold 1    0   1   1  \n",
       "fold 2    0   1   1  \n",
       "fold 3    0   1   0  \n",
       "fold 4    0   0   0  \n",
       "fold 5    1   0   1  \n",
       "fold 6    0   0   1  \n",
       "fold 7    0   1   0  \n",
       "fold 8    0   0   1  \n",
       "fold 9    1   0   0  \n",
       "fold 10   1   0   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = DataFrame([np.tile([0, 1], 10)], index=['target'])\n",
    "predictions = DataFrame(np.random.randint(0, 2, size=(10, 20)), index=[f'fold {i+1}' for i in range(10)])\n",
    "\n",
    "display(y)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\"><tr><td style=\"text-align:center\">Crossvalidation telemetry</td></tr><tr><td style=\"vertical-align:top\"> <table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>training_error</th>\n",
       "      <th>test_error</th>\n",
       "      <th>optimism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>fold 1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 2</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 3</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 4</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 7</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 8</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 9</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fold 10</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></tr></table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "S = np.full(10, np.nan)\n",
    "E = np.full(10, np.nan)\n",
    "Delta = np.full(10, np.nan)\n",
    "for i in range(10):\n",
    "    test_fold = [20 - 2*i - 2, 20 - 2*i - 1] \n",
    "    training_fold = [i for i in range(20) if i not in test_fold]\n",
    "    E[i] = np.mean(y.iloc[0, test_fold] != predictions.iloc[i, test_fold])\n",
    "    S[i] = np.mean(y.iloc[0, training_fold] != predictions.iloc[i, training_fold])\n",
    "    Delta[i] = E[i] - S[i]    \n",
    "\n",
    "measurements = DataFrame({'training_error': S, 'test_error': E, 'optimism': Delta}, index=predictions.index)\n",
    "mdisplay([measurements.reset_index()],['Crossvalidation telemetry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive 95% confidence intervals\n",
      "Training error: 0.494 ± 0.097\n",
      "Test error:     0.650 ± 0.153\n",
      "Optimism:       0.156 ± 0.192\n"
     ]
    }
   ],
   "source": [
    "print('Naive 95% confidence intervals')\n",
    "print(f\"Training error: {measurements['training_error'].mean():.3f} ± {2*np.std(measurements['training_error'], ddof=1)/np.sqrt(10):.3f}\")\n",
    "print(f\"Test error:     {measurements['test_error'].mean():.3f} ± {2*np.std(measurements['test_error'], ddof=1)/np.sqrt(10):.3f}\")\n",
    "print(f\"Optimism:       {measurements['optimism'].mean():.3f} ± {2*np.std(measurements['optimism'], ddof=1)/np.sqrt(10):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `scipy.stats.norm` and its `ppf` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40406177, 0.58482712])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(q=[0.025, 0.975], loc = measurements['training_error'].mean(), scale=np.std(measurements['training_error'])/np.sqrt(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Percent point function (inverse of `cdf`) at q of the given RV.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "q : array_like\n",
       "    lower tail probability\n",
       "arg1, arg2, arg3,... : array_like\n",
       "    The shape parameter(s) for the distribution (see docstring of the\n",
       "    instance object for more information)\n",
       "loc : array_like, optional\n",
       "    location parameter (default=0)\n",
       "scale : array_like, optional\n",
       "    scale parameter (default=1)\n",
       "\n",
       "Returns\n",
       "-------\n",
       "x : array_like\n",
       "    quantile corresponding to the lower tail probability q.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Library/miniforge3/envs/huggingface/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?norm.ppf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa645a3d-1498-4b62-aec0-91c3191a2f67",
   "metadata": {},
   "source": [
    "# Empirical risk minimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37eea4cf-501d-4706-b54e-0c690b16489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf96f8d-3a7f-482f-9ac9-347fe0d6246a",
   "metadata": {},
   "source": [
    "## I.  Majority voting algorithm\n",
    "\n",
    "* Our implementation corresponds to `sklearn` prediction API:\n",
    "  * constructor for fixing free hyperparameters\n",
    "  * method `fit(samples, targets)` to train the model\n",
    "  * method `predict(samples)` to predict labels\n",
    "  * method `set_params(...)` to set hyperparameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf142e04-8a1a-4f29-9bd7-408af1083969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoting:\n",
    "    \n",
    "    def __init__(self, features:List[str]=None):\n",
    "        if features:\n",
    "            self.features = list(features)\n",
    "        else:\n",
    "            self.features = None\n",
    "    \n",
    "    def set_params(features: List[str]) -> None:\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X: DataFrame, y: Series) -> None:\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = list(X.columns.values)\n",
    "\n",
    "        data = X.assign(y = y)\n",
    "        pred = data.groupby(self.features).aggregate(['count', 'sum'])\n",
    "        pred.columns = pred.columns.droplevel(0)\n",
    "        self.pred = DataFrame({'prediction':(pred['sum']/pred['count'] >= 0.5)})\n",
    "    \n",
    "    def predict(self, X: DataFrame) -> np.array:\n",
    "        \n",
    "        return (X[self.features]\n",
    "                .join(self.pred, on=self.features, how='left')['prediction']\n",
    "                .fillna(True)\n",
    "                .values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b082d-d5fe-42d4-8b04-dde86e682b43",
   "metadata": {},
   "source": [
    "# Homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff901dd-2d24-4056-9388-26db138cab56",
   "metadata": {},
   "source": [
    "## 2.1 Classifier that minimises empirical risk (<font color='red'>1p</font>)\n",
    "\n",
    "Given enough information about future data samples, it is possible to find a class with optimal accuracy.\n",
    "* Extend `MajorityVoting` algorithm for multi-label classification task and apply it to the data frame `data` below.\n",
    "* Predict `z` for  `x` and `y` and show the corresponding table of rules.\n",
    "* What is the corresponding risk if it is defined as the probability of misclassification on `data`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136ee5ab-6084-43a1-a154-4ddcd00359a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y  z\n",
       "0  1  0  2\n",
       "1  1  0  0\n",
       "2  3  1  1\n",
       "3  3  1  1\n",
       "4  3  1  2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = (DataFrame([(0, 0, 0), (0, 0, 1), (0, 0, 1), (0, 1, 2), (0, 1, 2),\n",
    "                  (1, 0, 1), (1, 0, 0), (1, 0, 2), (2, 0, 1), \n",
    "                  (2, 1, 0), (2, 1, 0), (2, 1, 0), \n",
    "                  (3, 1, 1), (3, 1, 1), (3, 1, 1), (3, 1, 2)], columns = ['x', 'y', 'z'])\n",
    "        .sample(frac=1).reset_index(drop = True))\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac782b-22ad-449b-ac5a-e38e21c9c34c",
   "metadata": {},
   "source": [
    "## 2.2. Theoretical analysis of majority voting$^*$ (<font color='red'>3p</font>) \n",
    "\n",
    "Explain why the training accuracy is so high for majority voting. \n",
    "You can give a theoretical answer or design an experiment to answer the following questions. \n",
    "You can consider the extreme case where the features $x_i\\in\\{0,1\\}$ and labels $y\\in\\{0,1\\}$ are sampled randomly. \n",
    "\n",
    "* Give a rough estimate how many samples are needed to arrive to the situation where training error is roughly the same as test error. \n",
    " \n",
    "* How does the sample size depend on the number of dimensions? \n",
    "* What changes if some feature values are more probable than the others? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
